import subprocess
import torch
import time
import ffmpeg
from moviepy.editor import VideoFileClip, AudioFileClip

# input ë¹„ë””ì˜¤ íŒŒì¼ ì ˆëŒ€ ê²½ë¡œ
VIDEO_PATH = "/home/jaegun/projects/knu_project/VideoLLaMA3/assets/videos/dog.mp4"
# YuE outputì´ ìƒì„±ë  í´ë”ì™€ mp3 ì´ë¦„ 
GENERATED_AUDIO_PATH = "/home/jaegun/projects/knu_project/main/output/YuE_generated.mp3"
# ë¹„ë””ì˜¤ì™€ ìŒì„±ì´ í†µí•©ë  ìµœì¢… output í´ë”ì™€ mp4 ì´ë¦„ 
OUTPUT_VIDEO_PATH = "/home/jaegun/projects/knu_project/main/output/dog_final_output.mp4"

# ëª…ë ¹ì–´ ì‹¤í–‰ ì ˆëŒ€ ê²½ë¡œ
VIDEOLLAMA_CMD = ["python", "/home/jaegun/projects/knu_project/VideoLLaMA3/inference/250310_example1.py"]
YUE_INFERENCE_PATH = "/home/jaegun/projects/knu_project/YuE/inference"
                                    

def get_video_duration(video_path):
    """ ë¹„ë””ì˜¤ ê¸¸ì´ë¥¼ ê°€ì ¸ì˜¤ëŠ” í•¨ìˆ˜ """
    try:
        probe = ffmpeg.probe(video_path)
        return float(probe['format']['duration'])
    except Exception as e:
        print(f"âŒ Error getting video duration: {e}")
        return None


def run_command(command, cwd=None):
    """ ì„œë¸Œ í”„ë¡œì„¸ìŠ¤ë¥¼ ì‹¤í–‰í•˜ê³ , ì‹¤ì‹œê°„ ì¶œë ¥ì„ í™”ë©´ì— í‘œì‹œí•˜ëŠ” í•¨ìˆ˜ """
    with subprocess.Popen(command, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, bufsize=1) as p:
        for line in p.stdout:
            print(line, end="")  # ì‹¤ì‹œê°„ ì¶œë ¥
        return line


def merge_video_audio(video_path, audio_path, output_path):
    """ MoviePyë¥¼ ì‚¬ìš©í•˜ì—¬ ë¹„ë””ì˜¤ì™€ ì˜¤ë””ì˜¤ë¥¼ ë³‘í•©í•˜ëŠ” í•¨ìˆ˜ """
    print("\nğŸ¬ ë¹„ë””ì˜¤ì™€ ìƒì„±ëœ ë°°ê²½ ìŒì•…ì„ ë³‘í•©í•˜ëŠ” ì¤‘...")

    video_clip = VideoFileClip(video_path)
    audio_clip = AudioFileClip(audio_path)

    final_clip = video_clip.set_audio(audio_clip)
    final_clip.write_videofile(output_path, fps=video_clip.fps)  # FPS ìœ ì§€

    video_clip.close()
    audio_clip.close()

    print(f"âœ… ìµœì¢… ë¹„ë””ì˜¤ ì €ì¥ ìœ„ì¹˜: {output_path}")


if __name__ == "__main__":
    start_time = time.time()  # ì „ì²´ ì‹¤í–‰ ì‹œê°„ ì¸¡ì • ì‹œì‘

    # ğŸ”¹ 1. ë¹„ë””ì˜¤ ê¸¸ì´ ê°€ì ¸ì˜¤ê¸°
    video_duration = get_video_duration(VIDEO_PATH)
    if video_duration is None:
        print("âŒ Failed to get video duration. Exiting...")
        exit(1)

    print(f"\nğŸ¥ Video Duration: {video_duration:.2f} seconds")

    # ğŸ”¹ 2. VideoLLaMA3 ì‹¤í–‰
    print("\nğŸš€ Running VideoLLaMA3 to generate music genre tags...")
    line = run_command(VIDEOLLAMA_CMD)

    # VideoLLaMA3 ì¶œë ¥ê°’ì—ì„œ genre íƒœê·¸ ê°€ì ¸ì˜¤ê¸°
    generated_tags = line.strip()
    print(f"\nğŸµ Generated Genre Tags: {generated_tags}")

    # ğŸ”¹ 3. YuE ì‹¤í–‰í•˜ì—¬ ë°°ê²½ ìŒì•… ìƒì„±
    print("\nğŸš€ Running YuE to generate background music...")

    yue_cmd = [
        "python", "250310_infer_copy.py",
        "--genre", generated_tags,
        "--lyrics_txt", "/home/jaegun/projects/knu_project/YuE/prompt_egs/lyrics copy.txt",
        "--cuda_idx", "0",
        "--stage1_model", "m-a-p/YuE-s1-7B-anneal-en-cot",
        "--stage2_model", "m-a-p/YuE-s2-1B-general",
        "--run_n_segments", "1",
        "--stage2_batch_size", "4",
        "--output_dir", "/home/jaegun/projects/knu_project/main/output",
        "--max_new_tokens", str(int(video_duration * (3000 / 50))),  # ğŸ¯ ë¹„ë””ì˜¤ ê¸¸ì´ì— ë§ê²Œ ë™ì  ì¡°ì •
        "--repetition_penalty", "1.1"
    ]

    run_command(yue_cmd, cwd=YUE_INFERENCE_PATH)

    # ğŸ”¹ 4. ë¹„ë””ì˜¤ + ì˜¤ë””ì˜¤ ë³‘í•©
    merge_video_audio(VIDEO_PATH, GENERATED_AUDIO_PATH, OUTPUT_VIDEO_PATH)

    print("\nğŸ¬ Your video now has a background music file that matches its length!")
